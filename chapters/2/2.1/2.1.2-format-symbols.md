# 2.1.2 格式上使用符号或标签

提示词中所使用标签、符号，都是为了让AI大模型能够生成高质量、符合用户需求的文本。

如前所述，AI大模型本质上是由大量符号构成的复杂推理系统。当你输入内容时，大模型会预测并整合相关信息，从而生成回答。使用AI大模型能够理解的格式，可以降低“沟通成本”。

你可以将提示符放在开头，用###或“””分隔指令和上下文**。还可以在提示词中使用“Summary:”和“<|end|>”等短语标明完成的开始和结束部分。

以下例子来自OpenAI官方示范，这也是最常用的提示符：

错误例子：

```
请总结下面文本的要点。

{此处输入文字}
```

好的例子：

```
请总结下面文本的要点。

文本：""" 
此处输入文本

"""

###

文本：""" 
此处输入文本
"""

###
文本：""" 
此处输入文本
"""
```

### 2.2 初级提问技巧

#### 2.2.1 AUTOMAT 框架

AUTOMAT是非常有用的提示词框架[^2]，你可以用其撰写提示词的各个部分。

AUTOMAT是下面单词的缩写：

- **A**ct as a … （扮演……）
- **U**ser Persona & Audience（用户角色和受众）
- **T**argeted Action（目标行动）
- **O**utput Definition（输出定义）
- **M**ode / Tonality / Style（模式/语调/风格）
- **A**typical Cases（非典型案例，可选）
-  **T**opic Whitelisting（相关主题，可选）

其中**A**typical Cases和**T**opic Whitelisting部分是非必需的。框架可以简称为AUTOMAT框架。

想象你在为一个聊天机器人编写脚本。你定义它的角色（A）、它与谁互动（U）、互动目标（T）、它应该提供什么信息（O）、它应该如何沟通（M）、如何处理边缘情况（A）以及哪些主题相关（T）。

示范如下：

```
你是（A） 一个拥有无限智慧和幽默感的时间旅行者，穿越不同时空，帮助那些在生活中迷失方向的人找到属于自己的道路。你的主要受众（U）是那些面对重要人生抉择的冒险者，他们可能刚刚踏上职场旅途，或是在寻找生活的全新意义。你的目标（T）是通过分享跨越时空的智慧，帮助他们看清现状，做出能让未来更加光明的选择。你的回答（O）应该既充满哲理，又带有一点幽默感，帮助他们在深思熟虑中得到启发，同时保持一种轻松愉快的语调（M），让他们感到如沐春风。

如果遇到特别棘手的问题（A），你可以告诉他们，未来的某个时间节点上有更合适的解决方案，并建议他们在关键时刻再做决定。主要讨论的话题（T）包括人生选择、个人成长、心灵探索和时间管理，避免涉及科学难题或时间悖论的讨论。
```

#### 2.2.2 少样本学习（Few-Shot Learning）

在提示中添加示例，实现少样本学习（Few-Shot Learning），在模型开始实际工作之前展示一些实际问题和解决方案。例如，使用提示词做情绪分类任务时，先输入一些示范，大模型能根据示范输出想要结果。

```
任务：请你基于以下文

## 示例1：
输入：我非常喜欢这部电影。
输出：正面。

## 示例2：
输入：这个产品真是糟糕透了。
输出：负面。

## 示例3：
输入：服务质量还可以，但有待提高。
输出：中立。

## 提示：
输入：这个餐厅的食物很美味。
输出：
```

### 2.3 进阶提问技巧

#### 2.3.1 思维链提示（Chain-of-Thought Prompting）

引导大模型给出推理步骤（“请你一步步思考”），思维链提示鼓励模型先阐述每一步推理的逻辑，从而更容易追踪推理过程，发现并纠正潜在错误。这种方法特别适用于复杂问题解决、数学计算、逻辑推理等任务。

```
一个箱子里有42个苹果，另一个箱子里有36个苹果。两箱苹果共有多少个？让我们一步步思考。
```

再举一个例子，提示词中加入“让我们一步步思考”，AI大模型在回答问题时，会展示解题过程：

```
小明、小红和小张都喜欢不同的水果：苹果、香蕉和橙子。已知：小明不喜欢橙子，小红喜欢香蕉。那么谁喜欢苹果？请你一步步思考。
```

#### 2.3.2 ReAct框架（Reasoning and Acting）

ReAct框架是一种结合推理（Reasoning）和行动（Acting）的高级提示策略，用于引导任务的分步解决，特别适合需要多步骤推理和信息查询的复杂任务。

该方法让AI大模型模拟人类的“思考-行动-观察”循环，以便更能够灵活地解答复杂任务。在回答一个复杂的问题时，ReAct框架可能会这样工作：

- 推理：分析问题，确定需要查找的信息。
- 行动：模拟搜索或查询相关信息。
- 推理：基于获得的信息进行进一步分析。
- 行动：根据分析结果采取下一步行动或给出最终答案。

这个循环可以根据需要重复多次，直到问题被完全解决。

下图对比了四种提示词方法，可见ReAct（推理加行动）比其他方法更有效地完成复杂任务。

![ch01.003](/Users/john/Desktop/AIUG/book/Images /ch01.003.jpeg)

*图片来源：[ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/abs/2210.03629)*

### 2.4 提示词示例

此处分享常见的七个提示词，我们整理了99个最精彩的提示词，涵盖知识工作者常见的8个场景。具体可查看网站。

**（1）苏格拉底式提问**

像苏格拉底一样问问题，引导你深入思考某个问题。

```
我想做一个AI相关的产品，请你以苏格拉底的方式对我进行提问，一次一个问题。

```

**（2）同时扮演多个角色进行对话**

同时扮演某个领域的专家和新手，AI大模型自己和自己对话，掌握该领域最关键的知识。这个方法适合用来学习任何新的领域。

```
## 角色设定：
- 角色A：SEO专家，行业经验丰富，精通各种SEO技巧，从基础到高级策略都了如指掌。你擅长将复杂的概念用简单易懂的方式解释，并能够给出实用的建议和指导。
- 角色B：SEO小白，对SEO的基本概念略有了解，但缺乏实战经验，渴望学习SEO的核心知识和操作技巧。你对这个领域充满兴趣，希望在短时间内掌握SEO的关键内容。

## 对话目标：

在90分钟内，角色A要向角色B传授SEO的核心知识，包括但不限于：SEO的基础概念、关键字研究、页面优化、内容策略、外链建设、技术SEO，以及最新的SEO趋势。角色B需要通过提问来引导角色A讲解，并在过程中提出自己的疑问和想法。

## 对话场景：
角色B找到角色A，希望得到SEO方面的指导，特别是想要掌握实操技巧，并希望老师能够传授一些行之有效的策略。角色A则需要根据B的需求，制定一套系统的教学方案，并在对话中一步步讲解。

请你来回扮演角色A、角色B展开对话。注意对话时长是90分钟。

```

**（3）翻译**

扮演专业的语言翻译，把文字从一种语言翻译为另外一种语言。

```
你是一位精通AI领域的专业翻译，擅长将外语文章翻译成简体中文。

请遵循以下要求进行翻译：\n1)通读原文，理解其大意、背景和语言风格。\n2)翻译时确保信息完整，忠实于原文的风格和语气，语言流畅自然。\n3)调整语序，注意句子结构，使其符合汉语规则和阅读习惯。\n4)关注专业术语，确保翻译质量达到中文翻译的前95%。\n5)第一次翻译后，请进行二次翻译，

步骤如下：\n1)反思第一次翻译的结果。\n2)采用意译方法，避免直译，准确传达原文的含义。\n3)确保译文更加流畅自然、地道易懂，改写任何可能让中文母语人士觉得不通顺的地方。\n4)注意译文中的长句断句和常见词汇的使用，如“你的”、“我的”、“其”、“之一”、“并”、“一个”、“通过”等，确保符合汉语语法和语序。\n5)翻译质量应超过《经济学人》、《科学美国人》（Scientific American）、《环球科学》等顶尖杂志的中文翻译水平。

只输出二次翻译的结果。

以下是需要翻译的文章：{
	
	
	
}
```

**（4）修改代码**

充当产品开发专家，用来检查代码错误，辅助编程。

```
您是一位专家级Python开发人员，拥有多年编写Python代码以及向其他程序员教授Python的经验。你现在是我学习Python的导师。

请评价这段代码是否正确，是否符合最佳编程风格。如果不符合请纠正，并指出修改的地方。

代码"""


"""
```

**（5）担任人生发展教练**

为压力管理、情绪管理提供专业建议。

```
我想让你充当人生教练。我将提供一些关于我目前的情况和目标的细节，而你的工作就是提出可以帮助我做出更好的决定并实现这些目标的策略。这可能涉及就各种主题提供建议，例如制定成功计划或处理困难情绪。我的第一个请求是“我需要帮助养成更健康的压力管理习惯。”

```

**（6）总结会议纪要**

总结会议纪要。只需要把会议记录发给AI大模型，AI大模型便可以快速总结会议纪要。

```
你是一位专业的会议记录助手，专注于整理和生成高质量的会议纪要，确保会议目标和行动计划清晰明确。你需要全面记录会议内容，准确表述每个方面，包括议题、讨论、决定和行动计划。确保语言流畅、易于理解，使每位参会人员都能清晰掌握会议的框架和结论。

简洁专业的语言：信息要点明确，不进行过多解释；使用专业术语和格式。

对于语音会议记录，先将语音转成文字，然后需要你将转录的文本整理成逻辑清晰、内容明确的会议纪要，去除口语表达。

## 工作流程:

- 输入: 通过开场白引导用户提供会议讨论的基本信息。
- 整理: 按照以下框架整理用户提供的会议信息，每个步骤后进行数据校验以确保准确性：
- 会议主题：会议的标题和目的。
- 会议日期和时间：会议的具体日期和时间。
- 参会人员：列出所有参会人员。
- 记录者：注明记录内容的人。
- 会议议程：列出会议的所有主题和讨论点。
- 主要讨论：详述每个议题的讨论内容，包括提出的问题、提议、观点等。
- 决定和行动计划：列出会议的决定、行动计划、负责人及完成日期。
- 下一步打算：列出未来计划或需要在下一次会议中讨论的问题。
- 输出: 输出结构清晰、描述完整的会议纪要。

## 注意:

- 整理会议纪要时需确保信息准确，不对用户提供的内容进行扩写。
- 仅做信息整理，对明显的病句进行微调。
- 会议纪要：详细记录会议讨论、决定和行动计划的文档。
- 只有在用户提问时才开始回答，用户未提问时请保持沉默。

## 初始语句: "你好，我是会议纪要整理助手，将会议文本交给我，我将为您生成简洁且专业的会议纪要！"

```

**（7）充当教学专家**

当你遇到一个新概念时，可以让AI大模型解释。可以让AI大模型采用高中生能听懂的语言、或者形象化解释。

```
请你作为一位教学专家，解释以下概念。首先，提供一个简洁的定义，然后用一个实际的例子说明这个概念的应用。最后，描述这个概念在日常生活中的重要性或影响。你的解释应该清晰易懂，适合初学者。

[插入概念]

```

## 3. AI大模型初级运用

前面我们介绍了，你只需要在对话界面输入提示词，就可以和AI大模型对话，这种方法操作起来非常简单方便。建议你直接动手操作，融合在日常工作中。

### 3.1 把AI嵌入你的工作流

与其恐慌和焦虑，不如马上把AI嵌入工作流程。本节将探讨如何选择大模型、把AI大模型潜入工作流程方法。

#### 3.1.1 使用何种大模型

使用AI大模型时，首先要明确在哪里使用以及使用哪一个模型。目前主要有两种方式：通过大模型公司提供的官方界面使用单一模型，或使用第三方服务集成多个模型。

| 使用方式           | 优点                       | 缺点                                   |
| ------------------ | -------------------------- | -------------------------------------- |
| 单一大模型         | 打开界面即可使用，无需配置 | 隐私数据泄漏，数据可能被用于训练大模型 |
| 集成使用多个大模型 | 根据需求和成本切换大模型   | 需要技术基础                           |

单一大模型的使用方法直接简单。以ChatGPT为例，用户只需访问chat.openAI.com，注册并登录后即可开始对话，不登陆可使用临时会话。ChatGPT提供GPT-4o-mini和GPT-4o两个版本，前者免费使用，后者需要Plus会员。ChatGPT不仅支持文本输入、还支持上传文件、分析图片。

| **模型名称**      | **界面特点**                      | **界面链接**                                                 |
| ----------------- | --------------------------------- | ------------------------------------------------------------ |
| ChatGPT           | 界面简洁，支持会话历史显示        | [ChatGPT](https://chat.openAI.com)                         |
| Google Gemini     | 类似搜索引擎，结合AI对话功能    | [Google Bard](https://gemini.google.com/)                       |
| Claude            | 界面简洁，专注隐私和安全          | [Claude AI](https://claude.ai)                           |
| 微软 Copilot      | 深度集成于 Office，帮助提高生产力 | [Microsoft Copilot](https://www.microsoft.com/microsoft-365/copilot) |
| 百度 文心一言     | 中文优化的界面，结合百度搜索功能  | [文心一言](https://yiyan.baidu.com)                        |
| 阿里巴巴 通义千问 | 面向企业应用，界面简洁实用        | [通义千问](https://tongyi.aliyun.com)                        |
| 月之暗面 Kimi     | 支持20万字，界面简洁              | [Kimi](https://kimi.moonshot.cn/)                            |

每个模型能力、使用成本有所不同，GPT-4是最强大的模型，但是其使用成本高昂，对于一些简单任务，我们可以选择其他模型。这时来回在不同模型对话界面切换，就显得复杂。

这就引出了第二种使用方式：多模型集成服务。

你只需要把各个大模型公司的API，填入第三方平台，即可来回切换。API相当于钥匙，你只要填入第三方运用窗口，就可以开始使用。你可以根据执行的任务以及成本，灵活切换对应的大模型。例如，使用Claude编程能实时显示编写结果。

API需要在大模型公司官网申请。以OpenAI为例，用户登录openai.com后，可在API部分创建新的密钥。可以设置使用限额以控制成本，并妥善保存密钥。

以下是常见的第三方服务平台，有的平台不需要自己填写API，只需要按需要购买额度，即可使用多个大模型。

| 名称 | 网址 | 描述 |
|------|------|------|
| LobeChat | https://chat-preview.lobehub.com/chat | 支持主流AI大模型、支持上传文件和多模态（Vision/TTS），并且还有插件。直接进入官网即可使用，使用方便。而且支持本地AI大模型。 |
| Poe | https://poe.com/ | 支持主流AI大模型，社区提供了众多聊天机器人，还可以自己创建聊天机器人。您能够通过浏览器配置和运行自主的AI代理。 |
| coze | https://www.coze.com/home | 一个无需编码的 AI 机器人开发平台，可以为机器人配备各种工具、自定义技能、知识库、记忆功能等。操作简单。 |
| ChatGPT-Next-Web | https://app.nextchat.dev/ | 一款易于部署的跨平台AI聊天应用，支持多种语言模型和丰富的自定义功能。平台仅支持发送文字，不支持图片。 |
| chatbox | https://chatboxai.app | AI客户端应用和智能助手，支持所有主流模型的API，可在所有平台上使用。 |

#### 3.1.2 如何嵌入工作流中

目前已经了解了各个AI大模型的能力，知道了在哪里使用它们。接下来是如何把AI大模型与工作流融合。

这个过程分为三个步骤：梳理工作任务、识别可与AI结合的环节、在这些环节使用AI。

**（1）梳理工作任务**

首先，仔细审视你的日常工作。以市场营销为例，你的工作可能包括市场调研、竞品分析、策略制定、内容创作和数据分析等。列出这些任务，为下一步做准备。

**（2）识别可与AI结合的环节**

审视你的任务列表，找出那些耗时、重复性高、需要处理大量信息或需要创意激发的任务。这些往往是AI能够发挥最大价值的地方。例如：

| 工作环节 | AI 应用 |
|----------|---------|
| 市场调研 | AI可以快速总结大量报告和文章 |
| 竞品分析 | AI能高效比较不同产品特性 |
| 内容创作 | AI可以提供创意灵感和初稿 |
| 数据分析 | AI善于从海量数据中提取洞见 |

**（3）把AI融入工作流**

确定了结合点后，下一步是设计如何在这些环节中使用AI。

以内容创作为例，传统方法需要花费数小时头脑风暴，苦苦寻找灵感。但是融入AI后，告诉AI "为新产品X创作5个吸引25-35岁年轻人的标语"，几秒钟内获得多个创意方向，激发更多灵感。

![ch01.004](/Users/john/Desktop/AIUG/book/Images /ch01.004.jpeg)

上图直观展示了AI如何提升内容创作效率，有了AI，你可以将原本需要8小时的工作压缩到2小时左右，而且工作更具有创造性。

过程中要注意，先从一两个环节开始，逐步扩展，根据效果不断调整AI使用方式。应该将AI视为助手，不能代替人类做决策，内容应经过你自己审核。当然，在使用AI时，要注意保护敏感信息和知识产权。

通过这种方法，你可以有效地将AI融入工作流程，不断提升工作效率和创新能力。AI发展速度相当快，需要我们不断探索。

### 3.2 用AI辅助编程

有了AI大模型后，编程的门槛大大降低。

我们坚信，有了AI大模型，掌握编程将会拓展你的能力边界。我们把用AI辅助编程放在此部分，是为了强调其重要性。

AI简化了产品开发流程。以前需要大量时间开发的应用，现在可能只需要和AI对话就能快速构建。掌握AI编程将变得像读写能力，是未来社会的基础技能。

- 传统编程：学习编程知识—>手动编程—>遇到问题难以解决。这需要非常漫长的时间。
- 有了AI大模型后：问题—>向AI大模型描述—>AI大模型辅助编程。

开发者Javi Lopez借助GPT-4、Midjourney和DALL-E等AI工具，在短时间内仅用约600行代码就复制了类似"愤怒的小鸟"风格的游戏"Angry Pumpkins"。

你只需要说出你的需求，AI就可以快速构建一个运用，未来人人个性化的需求，都可以自己通过编程完成。据统计，约60%的专业开发者在日常编程中会使用AI编程工具，如微软的Copilot和字节跳动的CodeGPT。

AI在编程中的运用包括：充当编程导师，24小时耐心回答你编程有关的问题，不用搜索编程问题，这点对编程新手真的很有用；充当编程助理，直接帮助你编写程序。

使用AI进行编程时的环境准备：了解Pyhton（推荐使用）相关基础知识；编程助手：使用**ChatGPT**或者**Claude**的页面、专业的AI编程工具，如**Copilot、Cursor(推荐，非常好用)**等。

需要掌握的Python基础知识包括：理解编程是输入一系列计算机能够识别的语言，计算机处理后，输出结果。编程的基本思维是：模块化、自动化。把能够实现某个任务的编程，封装在一起。

以下举一个具体例子。你想编写一个有趣、炫酷的计算器程序，你可以在ChatGPT窗口告诉AI：

```
你是经验丰富的程序开发人员，请帮我编写一个有趣、操作起来简单，之前没有存在过的计算器。
```

AI便可以开始编程：

```
import tkinter as tk
from functools import partial

# 定义一个函数来处理按钮点击事件
def onClick(label, display):
    if label == "C":
        display.config(state=tk.NORMAL)
        display.delete(0, tk.END)
        display.insert(0, "0")
        display.config(state=tk.DISABLED)
    elif label == "=":
        try:
            result = eval(display.get())
            display.config(state=tk.NORMAL)
            display.delete(0, tk.END)
            display.insert(0, str(result))
            display.config(state=tk.DISABLED)
        except Exception as e:
            display.config(state=tk.NORMAL)
            display.delete(0, tk.END)
            display.insert(0, "Error")
            display.config(state=tk.DISABLED)
            
            （以下省略）
```

运行代码后就可以看到计算器了！而整个过程1分钟不到！

![ch01.005](/Users/john/Desktop/AIUG/book/Images /ch01.005.jpeg)

未来初中级的程序员价值变得越来越小了。赶快尝试起来吧，学习编程中你会遇大不少困难，但有AI助手在你身边，这一切将变得非常简单。

你可以尝试通过以下方式使用AI：

- 单一的任务，用AI写脚本，实现自动化。
- 学编程遇到问题直接问AI。
- 转换程序代码，例如把XX编程语言转为XX编程语言。

还有很多。用起来后会发现编程是多么有趣！

### 3.3 如何在本地运行大模型

运行大模型有三种方式，一种是直接在大模型公司提供的对话窗口运行，如OpenAI提供的聊天界面；一种是使用API——这是大模型公司提供对话钥匙。但是，这两种方式都需要联网，有可能会出现对话数据泄漏。

在有的环境下没有网络，或者对数据隐私要求非常高，这时怎么办？这就需要在本地运行大模型。

你可以把本地运行大模型理解为，把大模型下载在电脑本地使用，就像使用不需要联网也可以使用的APP一样。随着大模型生态发展，本地运行大模型对硬件要求、技术要求越来越低。

以下是几种本地运行大模型常见方法。

#### 3.3.1 Ollama + Anything/open-webui

Ollama是一个支持在本地运行大模型的工具，因其上手简单、支持各类扩展等优点，推出后迅速在开源社区广泛传播。

使用Ollama非常简单，分为三步：安装Ollama、下载模型、本地使用大模型对话。

第一步，安装Ollama：打开网址（网址：https://ollama.com/），点击下载按钮下载Ollama到本地。

第二步，下载模型：在终端打开ollama。启动后，使用Ollama run 模型名称，即可下载模型。

你可以根据任务要求以及电脑配置选择下载的模型，下图是社区下载次数最多的几个模型。

| 模型名称 | 可用参数规模 | 下载量 |
|----------|--------------|--------|
| llama3   | 8B, 70B      | 6.2M   |
| llama3.1 | 8B, 70B, 405B| 5.2M   |
| gemma    | 2B, 7B       | 4.1M   |
| qwen     | 0.5B, 1.8B, 4B, 32B, 72B, 110B | 4M |
| qwen2    | 0.5B, 1.5B, 7B, 72B | 3.5M |
| mistral  | 7B           | 3.4M   |
| phi3     | 3B, 14B      | 2.4M   |
| llama2   | 7B, 13B, 70B | 2.1M   |

*上图数据截止2024年9月20日*

注：*MAC电脑启动终端方法：点击屏幕右上角的搜索图标，输入"终端"，然后点击搜索结果中的终端应用即可打开。Windows电脑启动终端方法：按下Windows键+R键，在运行窗口中输入"cmd"，然后点击确定或按回车键即可打开命令提示符窗口。*

第三步，本地使用大模型对话：当模型下载完成后，直接使用`ollama run 模型名称`即可在终端与模型对话。如果在终端与模型对话不方便，推荐安装`Open WebUI`与大模型对话。

#### 3.3.2 Jan

Jan相比ollama，可以直接在界面下载开源大模型。使用起来非常简单：安装Jan、下载模型、本地使用大模型对话。

第一步，安装Jan：打开网址（网址：https://jan.AI/），点击下载按钮下载Jan到本地。

第二步，下载模型：按照下面提示，找到模型所在位置，下载你需要的模型。下载时，会提示你哪些模型因计算机硬件原因，难以下载。

第三步，本地使用大模型对话：下载后，打开对话窗口，即可展开对话。

Jan还支持本地知识库，可以上传个人文档，这些文档在本地使用，不用担心信息泄漏。

#### 3.3.3 LocalAI

LocalAI是一个开源工具，旨在在本地环境中运行大型语言模型，支持多种开源模型，可以通过Docker容器部署，并且提供了与 OpenAI API 兼容的接口。

LocalAI更适合开发者二次开发，具体可参考（https://localai.io/）。

本地运行大模型还支持上传文档，与文档对话，这些文档始终在电脑本地，处理文档也不需要消耗API。

如果你想获取更多本地运行大模型方法，可以参考这个链接：https://github.com/vince-lam/awesome-local-llms

## 4. AI大模型进阶运用

### 4.1 搭建个人知识库

想象一下，你手头有大量文档，你想快速知道这些文档的内容、内容之间的关联性，但是一个个阅读太费时间；或者你拥有某个牛人所有的资料，想模拟和这个牛人的对话，学习他的思想；或者你电脑上有一大堆法律文档，想快速找出相似案例，目前的检索方法不够高效。

面对这些情况，我们该如何处理呢?此时你可以用AI搭建一个知识库助手。

与搭建知识库密切相关的技术是RAG(Retrieval-Augmented Generation,检索增强生成)，核心原理是利用向量化技术，将语义相似的内容聚集在一起。语义相似是指含义相近，即使字面表达不同。例如输入“我很生气”，系统可能会找到“愤怒”、“恼火”、“气愤”等词，这些词虽然不同，但都表达了类似的情绪——生气，RAG可以将这些情绪词汇聚集在一起。

RAG的工作流程可以分为检索、增强、生成三个阶段。

当用户提出问题时，系统会从预先准备的知识库中**检索**相关文档。例如，对于"公司的年假政策是什么？"这个问题，系统会搜索包含休假政策信息的文档。接下来，从检索到的文档中提取到的关键信息，将其与用户的原始问题结合，形成一个**增强**的提示（prompt），这个提示包含了更丰富的上下文信息。最后，大模型使用这个增强后的提示来**生成**回答。由于提示中包含了特定的领域知识，生成的回答通常比仅依赖模型本身的知识更加准确。

![ch01.006](/Users/john/Desktop/AIUG/book/Images /ch01.006.jpeg)

以下是常用的RAG工具。这些工具在开源社区中备受关注，并且更新迭代速度较快。

| 序号 | 名称                 | 简介                                                         | GitHub 仓库地址                                        |
| ---- | -------------------- | ------------------------------------------------------------ | ------------------------------------------------------ |
| 1    | Dify                 | 开源LLM应用开发平台，提供AI工作流、RAG管道等直观界面。     | https://github.com/langgenius/dify                     |
| 2    | Quivr                | 你的第二大脑，利用 GenerativeAI 的力量成为您的个人助理！   | https://github.com/QuivrHQ/quivr                       |
| 3    | Open WebUI           | 面向 LLM 的用户友好型 WebUI                                  | https://github.com/open-webui/open-webui               |
| 4    | LangchAIn-Chatchat | 基于LangchAIn和ChatGLM等语言模型的RAG和Agent应用。         | https://github.com/chatchat-space/LangchAIn-Chatchat |
| 5    | chatgpt-on-wechat    | 支持多种平台接入的聊天机器人，支持多种语言模型。             | https://github.com/zhayujie/chatgpt-on-wechat          |
| 6    | anything-llm         | 一款全栈应用程序，可让您将任何文档、资源或内容转换为上下文。 | https://github.com/Mintplex-Labs/anything-llm          |
| 7    | FastGPT              | 一个基于LLM的知识平台，提供数据加工、RAG检索和视觉AI工作流编排等能力。 | https://github.com/labring/FastGPT                     |
| 8    | DocsGPT              | 一款先进的开源解决方案，可简化在项目文档中查找信息的过程。   | https://github.com/arc53/DocsGPT                       |
| 9    | RAGFlow              | 基于深度文档理解的开源 RAG（检索增强生成）引擎。             | https://github.com/infiniflow/ragflow                  |
| 10   | Reor                 | 私人和本地的AI个人知识管理应用程序。                       | https://github.com/reorproject/reor                    |
| 11   | haystack             | LLM编排框架是构建高级RAG、问答和对话机器人的定制化生产级应用的解决方案。 | https://github.com/deepset-AI/haystack               |

以RAGFlow为例，搭建个人知识库的流程如下：

- 打开官网（*网址：ragflow.io*）并注册账号。
- 创建项目：假如我想学习某位企业家的所有思想，我可以把他写的文章，接受采访的资源放入RAG，让AI模仿他的语气、思维方式回答问题。
- 上传文件（Add file）：上传准备好的资料，系统将自动对上传的文件进行向量化处理。
- 创建助手（Create an Assistant）：点击chat，然后选择"Create an Assistant"(创建助手)。按照系统指引，填写必要的配置信息。
- 开启聊天：配置完成后，就可以开始与你想学习的企业家对话了！这个AI助手将模仿这位企业家的思维方式和表达风格回答你的问题。回答问题时，会优先从上传的资料中检索信息回答问题。

除了RAGFlow外，FastGPT、Dify效果也不错，你可以根据需要选择。RAG还可以与本地化运行大模型工具相结合，实现本地RAG，可参考上一章节内容。

### 4.2 使用AI代理实现工作自动化

#### 4.2.1 为什么使用AI代理

在我们的日常生活和工作中，许多重复性的工作都可以通过自动化、半自动化提高效率。AI代理(AI Agent)是人工智能领域最重要的研究方向之一，它们的核心目标是为用户完成特定任务和自动化流程。在智能客服、自动化办公工具，AI代理都发挥着越来越重要的作用。

**AI代理（AI Agent）**像是一个"超级助手"，具备感知环境、处理信息和作出决策、采取行动的能力。例如，在一个文章翻译的AI代理，可以模拟人类翻译文章的思维过程，通过初次翻译、反思初次翻译结果、二次优化翻译的方式，大大提升翻译质量。

为什么要使用AI代理来完成这些任务呢？答案很简单：为了解放我们的双手，让我们能够将时间和精力集中在更具创造性的事情上。借助AI大模型，我们可以将复杂任务拆解为多个步骤，并让AI系统自动完成部分或者全部步骤。工作模式由原来的人+机器，变成了人+AI代理（AI Agent），个人生产效率将会大大提高。

著名AI专家吴恩达教授总结了AI代理（AI Agent）的四种主要设计模式：

1. **反思（Reflection）**：AI大模型自己对自己生成的输出进行检查，提出反馈和改进建议。例如，在软件开发中，一个模型负责编写代码，另一个模型则负责代码审查。通过反复调整，代码质量得到了显著提升。
2. **工具使用（Tool Use）**：AI代理能够使用各种外部工具来增强自身能力，例如利用搜索引擎获取信息，或通过调用API来执行特定功能。
3. **规划（Planning）**：分解复杂任务，根据任务需求自主选择合适的工具和步骤。这一功能目前还不完全成熟，但在某些场景中已经展现了相当惊人的效果。
4. **多智能体协作（Multiagent Collaboration）**：多个AI代理分工协作，扮演不同角色（如CEO、设计师等），共同完成复杂项目。

ChatDev（网址:https://github.com/OpenBMB/ChatDev）是一个由多个AI智能体组成的虚拟软件公司，里面的“员工”全部是不同AI智能体扮演的，包括CEO、程序员、测试人员、UI设计师等决策相互协作，共同完成复杂的开发工作。

这并非取代人类，而是协助人类工作。例如在邮件写作中，LLM可以生成初始内容，但仍需人工审核和调整，以确保内容的准确性和质量。这种人机协作模式既发挥了AI的效率，又保留了人类的判断力。

#### 4.2.2 用AI代理实现办公自动化

建立AI代理的难度与任务复杂度直接相关。对于简单任务，如检查文章错别字，可能只需要一个精心设计的提示词就能完成。而对于更复杂的任务，如自动化市场调研或个性化学习助手，则需要配置复杂的工作流，可能涉及多个AI模型的协作以及与外部数据源和系统的集成。

创建AI代理的工具如coze、Dify等。以coze为例，其官网上（*网址：coze.com*）已经创建了各种类型的AI代理，你可以直接使用，或者创建AI代理。创建AI代理的基本步骤包括：定义代理目标、设置知识库（可选）、配置对话流程、测试优化，即可使用。创建方法非常简单。

与AI代理密切相关的还有自动化工具，它们专注于重复任务的自动化和批量处理。除了常见的RPA工具外，还有许多开源自动化工具值得探索，如UiPath Community Edition和n8n.io等。

这里推荐n8n.io，这是一款免费开源的自动化工具，并且官网提供了大量文字和视频教程。

- n8n介绍视频：https://www.youtube.com/watch?v=1MwSoB0gnM4
- 使用教程：https://docs.n8n.io/try-it-out/quickstart/#step-two-open-a-workflow-template

### 4.3 微调实现特定任务的AI大模型

训练一个大型语言模型，通常需要投入数百万到上千万美元的成本，并需要一个经验丰富的工程师团队。这不仅对算力和能源有极高的要求，同时也是一项需要长期投入的复杂工程。对于大多数公司和研究团队来说，训练一个全新的大型模型并非最佳选择。于是，**微调大模型**成为一种更为现实且高效的路径，尤其是在拥有某个特定领域的独特数据时，微调可以将让模型能够解决特定领域的问题。

如果你拥有一个稀有的少数民族语言数据集，微调可以让大模型掌握这门语言，使用这个民族的语言回答问题。如果你希望模型能够生成特定风格的漫画，经过微调之后的模型将能够更符合你的艺术风格需求，输出你想要的漫画风格。

微调和RAG的区别是，微调是改变AI大模型的参数，RAG则不改变AI大模型的参数。

#### 4.3.1 微调大模型的经典应用

微调大模型的应用场景十分广泛，以下是几个典型的应用领域：

**医学领域**：在医疗保健行业，研究人员通过微调大模型，使其能够处理和生成专业的医学报告，帮助医生诊断疾病并推荐治疗方案。这种微调后的模型能够快速理解并处理复杂的医学术语，显著提升了医疗效率。

**金融领域**：金融机构通过对模型进行微调，训练出能够处理金融专有名词和复杂数据的AI模型。不仅可以生成金融报告，还可以进行市场趋势预测，为投资决策提供支持。

**少数民族语言**：通过微调使模型掌握那些资源稀缺、尚未被广泛学习的少数民族语言。

**艺术与设计**：如果你希望生成某位艺术家特有风格的画作，或者想要模型呈现某种漫画风格，通过微调，你可以将这些创意需求转化为模型的能力，获得更加个性化的输出。

#### 4.3.2 如何微调大模型

在了解了微调的广泛应用之后，接下来让我们探讨微调的具体操作过程。

微调并不是单一的一步到位的任务，通常包含多个环节，每一步都需要精细的操作和优化。接下来，我们以常见的第三方平台 **Replicate** 为例，讲解微调流程。

**第一步，明确微调目标**。你是希望模型能够更加智能地完成某个任务，还是希望它生成符合特定风格的内容？微调目标直接关系到微调过程中数据集的选择、参数的设定，以及最终模型的表现。

**第二步，准备数据集**。数据集是微调过程中最为关键的因素之一。它决定了模型微调后的能力和表现。数据集通常分为训练集和测试集：前者用于教会模型新技能，后者用于验证模型是否真正掌握了这些技能。微调的数据集格式有明确要求，JSON是最常用的格式。以下是JSON格式示范：

   ```
   
   {
      "input": "模型的输入内容",
      "output": "模型的期望输出"
   }
   
   ```

数据集的准备不仅需要涵盖你所期望的所有场景，还应当确保数据的多样性和高质量，以便模型能够适应广泛的实际应用。

**第三步，开始微调**。将数据集上传至平台，例如Replicate，并按照官方指引配置参数。你可以根据自己的需求选择微调方法，常用的微调方法是LORA（一种轻量化的微调技术）。微调参数的配置也至关重要，不同任务对参数要求可能会有所不同，因此通常需要反复调试。

**第四步，测试与优化**。微调完成后，测试模型的效果。你可以通过人工评估输出的质量，或者使用事先准备好的测试集进行性能评估。如果微调效果令人满意，可以进入下一步；若效果不佳，则可能需要重新调整数据集或微调参数，甚至考虑加入更多的训练数据。

**第五步，部署与分发**。微调完成且测试通过后，可以选择将模型部署到应用中，也可以通过平台如Replicate，将微调好的模型分享给他人使用。平台提供了简单便捷的发布功能，允许你轻松将模型推向更多用户。

值得一提的是，微调的应用不局限于文本模型。Replicate等平台还支持对图像、视频、音频等多媒体模型进行微调。这使得创作者不仅可以微调出会写作的AI，还可以定制出生成图片、音频，甚至是视频的模型.

如果你希望进一步探索微调的技术细节或寻找更多关于微调的资源，以下是几个常见的第三方平台，上面的文档提供了详细指引：

- [Replicate 官方文档](https://replicate.com)
- [Huggingface 官方文档](https://huggingface.co)
- [Cohere 官方文档](https://cohere.ai) 

### （3）AI大模型与更多融合

在AI技术迅猛发展的今天，大模型公司提供的大模型API就像“食材”。你可以用食材烹饪出各种各样的美食。

AI大模型与硬件的融合正在开启一个充满可能性的新世界。在机器人领域，我们已经看到了能够完成复杂动作的人形机器人。这些机器人不仅能进行简单的行走和奔跑，还能完成如跑酷和后空翻等高难度动作。它们的控制系统集成了先进的AI算法，能够实时分析环境、调整姿态，甚至在遇到意外情况时迅速作出反应。这种高度的灵活性和适应能力，使得它们在未来的救援、勘探等高风险环境中具有巨大的应用潜力。

在辅助视障人士方面，AI技术也带来了革命性的进展。新一代的AI视觉辅助设备不仅能识别文字和物品，还能理解复杂的场景。比如SORA的发布视频中的场景。结合AI的设备能实时翻译外语街道标识，让视障人士在国外旅行时也能独立自如。更令人惊叹的是，有些设备还能根据使用者的习惯和偏好，逐渐调整描述的详细程度和侧重点，提供真正个性化的体验。

在儿童教育领域，AI与玩具的结合开创了新的可能性。AI玩具它不仅能和孩子对话，还能根据孩子的年龄、知识水平和兴趣爱好，实时调整互动内容。目前已经在市场上有售卖。例如，它可以根据孩子的反应调整故事的难度和主题，或者在数学游戏中动态调整题目难度。更有趣的是，这个玩具还能记住孩子最近学过的知识点，在日常对话中巧妙地融入这些内容，强化学习效果。

这些例子仅仅是冰山一角。随着AI大模型与各行各业的深度融合，我们正在见证一场前所未有的创新浪潮。从提高生产效率到改善生活品质，AI大模型正在以我们难以想象的方式重塑世界。

在这个AI与各个行业不断融合的新时代，新的可能正等待我们去探索和实现。

## 后记

你已经读到这里了，很棒！你可能已经对AI大模型有了初步的了解。相信你正跃跃欲试，想要用ChatGPT来协助工作，或用DALL-E为创意项目生成图像。这很好，AI确实能为我们的生活和工作带来前所未有的便利。

在开始你的AI之旅时，有几点值得注意。AI虽然强大，但并非万能。我使用ChatGPT写作时，它提供了很棒的灵感，但有时也会产生事实性错误。保持批判性思维，验证AI生成的信息是必要的。

保护隐私同样不容忽视。使用AI工具时，要谨慎对待个人敏感信息。不要把个人敏感信息和数据输入AI大模型，同样不得侵犯他人的隐私、版权。

希望本书为你打开AI的大门有所帮助。期待你立刻用起AI工具，并分享你的使用经验。

AI是强大的工具，但最精彩的故事，永远由你来书写。

## 备查表

### 备查表1：常用的 AI 生产力工具（21个）

#### 通用
1. **ChatGPT**：由OpenAI开发的强大聊天机器人，可以生成和优化文本，支持多种应用场景。
   链接：[ChatGPT](https://openAI.com/chatgpt)

2. **Claude**：Anthropic推出的全新一代聊天机器人，支持多轮对话，编写脚本。
   链接：[Claude](https://claude.ai/)

3. **Genmini**：轻松对话，让 Google AI 帮你写作、规划、学习或处理其他事务
   链接：[Jasper](https://gemini.google.com/)

#### AI生成文字工具
1. **Writesonic**：可以生成博客文章、广告文案等多种文本类型的AI工具。
   链接：[Writesonic](https://www.writesonic.com)
2. **Anyword**：基于AI的写作助手，提供数据驱动的文本生成和优化建议。
   链接：[Anyword](https://www.anyword.com)
3. **Grammarly**：提供强大的写作辅助功能，包括语法检查、拼写纠正、语调建议和风格优化。它不仅可以帮助提高写作质量，还能增强专业表达。
   链接：[Grammarly](https://www.grammarly.com)

#### AI生成图片工具
1. **Midjourney**：在Discord平台上运行的图像生成工具，以其创意和详细的图像质量著称。
   链接：[Midjourney](https://www.midjourney.com)

2. **Stable Diffusion**：通过DreamStudio提供广泛的自定义选项，用于生成图像。
   链接：[Stable Diffusion](https://www.stability.AI)
   
3. **DALL·E 3**：由OpenAI开发，可以根据文本描述生成高质量图像。
   链接：[DALL·E 3](https://www.openAI.com/dall-e-3)

#### AI生成视频工具
1. **Descript**：通过将视频转录为文本脚本来简化视频编辑过程。
   链接：[Descript](https://www.descript.com)

2. **Kling**：由快手大模型团队自研打造的视频生成大模型，具备强大的视频生成能力 让用户可以轻松高效地完成艺术视频创作。
   链接：[Kling](https://kling.kuaishou.com/)

3. **Runway**：提供生成视频能力和自定义AI模型训练的高级视频工具。
   链接：[Runway](https://www.runwayml.com)

#### AI生成3D工具
1. **Spline AI**：一个免费工具，根据文本提示生成场景、对象和动画。
   链接：[Spline AI](https://spline.design)

2. **3DFY.AI**：将文本提示转化为3D模型。
   链接：[3DFY.AI](https://3dfy.AI)

3. **DUSt3R**：开源3D视觉模型。
   链接：[DUSt3R](https://github.com/naver/dust3r/)

#### PPT制作工具
1. **Canva**：提供丰富的模板和设计工具，支持AI生成内容。
   链接：[Canva](https://www.canva.com)
   
2. **Beautiful.AI**：通过预设计的布局和样式简化幻灯片制作。
   链接：[Beautiful.AI](https://www.beautiful.AI)

3. **Tome**：基于AI的工具，帮助快速生成专业演示文稿。
   链接：[Tome](https://tome.app)

#### 数据分析工具
1. **Power BI**：微软提供的商业智能工具，整合AI功能用于数据分析和可视化。
   链接：[Power BI](https://powerbi.microsoft.com)
   
2. **Tableau**：强大的数据可视化工具，支持复杂的数据分析和报告生成。
   链接：[Tableau](https://www.tableau.com)
   
3. **Looker**：Google的商业智能平台，结合AI进行深入数据分析。
   链接：[Looker](https://looker.com)

### 备查表2：如何高效获取 AI 相关的信息

目前 AI 相关的信息非常多，但是99%的信息都不值得你去跟踪，都是二手三手信息，你需要做的是找到信息源头，用有限打败无限。

#### 通用

##### Github：快速获取开源项目

网址：https://github.com。

GitHub是全球最大的代码托管和协作平台，拥有大量GPT和LLM相关的开源项目和活跃的开发者社区，可以帮助开发者快速获取最新技术、参与项目并交流学习。

使用方法如下：

**技巧1：通过关键词和限定forks或者stars数量，从中筛选项目**

搜索created:>2023-03-01 stars:>=1000 label:gpt，即2023年3月1日后发布，关注量超过1000，关键词为GPT的项目，超过2000个。这2000多个项目，几乎代表了LLM领域最优质的开源项目，也代表了未来技术趋势。

但是这些项目数量太多，我们无法一一查看，那么我们可以通过下面方法缩小跟踪范围。

以下项目截止时间是2024年8月12日。

| 搜索关键词                                                   | 项目数量（个） | 链接                                                         |
| ------------------------------------------------------------ | -------------- | ------------------------------------------------------------ |
| created:>2023-03-01 stars:>=1000 label:gpt                   | 2000+          | https://github.com/search?q=created%3A%3E2023-03-01+stars%3A%3E%3D1000+label%3Agpt&type=Repositories&ref=advsearch&l=&l=&s=stars&o=desc |
| llm forks:>500                                               | 163            | https://github.com/search?q=llm+forks%3A%3E500+&type=repositories |
| gpt forks:>500                                               | 152            | https://github.com/search?q=gpt+forks%3A%3E500+&type=repositories |
| created:"> 2023-03-15" stars:>500 forks:>500 label:"gpt OR LLM OR rag OR Finetuning OR Gen AI " | 489            | https://github.com/search?q=created%3A%22%3E+2023-03-15%22+stars%3A%3E500+forks%3A%3E500+label%3A%22gpt+OR+LLM+OR+rag+OR+Finetuning+OR+GenAI%22&type=Repositories&ref=advsearch&l=&l= |

**项目推荐：**

Ollama：本地运行大模型管家，使用Ollama可以实现在本地运行大模型。支持主流大模型，还可以上传自己的大模型在Ollama上。项目地址：https://github.com/Ollama/Ollama

**技巧2：标签搜索法**

除了搜索标签外，还可以点击开源项目的标签，发现标签下的项目。进入后，可以选择多种方式进行排序。以下试举一些典型的：

- #llm。地址：https://github.com/topics/llm?o=desc&s=stars
- #AI 。地址：https://github.com/topics/AI
- #rag。地址：https://github.com/topics/rag
- #fine-tuning。地址：https://github.com/topics/fine-tuning
- #agents。地址：https://github.com/topics/agents

例如，根据标星数量和更新时间，可以筛选出关注度最高的RAG项目。你可以近似认为，这些RAG项目，代表了市场上最主流的RAG项目。

| 序号 | 名称               | 简介                                                         | GitHub 仓库地址                                      |
| ---- | ------------------ | ------------------------------------------------------------ | ---------------------------------------------------- |
| 1    | Dify               | 开源LLM应用开发平台，提供AI工作流、RAG管道等直观界面。       | https://github.com/langgenius/dify                   |
| 2    | Quivr              | 你的第二大脑，利用 GenerativeAI 的力量成为您的个人助理！     | https://github.com/QuivrHQ/quivr                     |
| 3    | Open WebUI         | 面向 LLM 的用户友好型 WebUI                                  | https://github.com/open-webui/open-webui             |
| 4    | Langchain-Chatchat | 基于Langchain和ChatGLM等语言模型的RAG和Agent应用。           | https://github.com/chatchat-space/Langchain-Chatchat |
| 5    | chatgpt-on-wechat  | 支持多种平台接入的聊天机器人，支持多种语言模型。             | https://github.com/zhayujie/chatgpt-on-wechat        |
| 6    | anything-llm       | 一款全栈应用程序，可让您将任何文档、资源或内容转换为上下文   | https://github.com/Mintplex-Labs/anything-llm        |
| 7    | FastGPT            | 一个基于LLM的知识平台，提供数据加工、RAG检索和视觉AI工作流编排等能力。 | https://github.com/labring/FastGPT                   |
| 8    | RAGFlow            | 基于深度文档理解的开源 RAG（检索增强生成）引擎。             | https://github.com/infiniflow/ragflow                |

**技巧3：更多**

跟踪趋势：跟踪Github上开发者、开源项目的热门趋势。可以跟踪当天、当周、当月热门趋势。网址：https://github.com/trending

中国用户可以关注推荐Github项目的国内公众号，我日常关注的有：逛逛Github、HelloGitHub、GitHubDAIly。

善用Awesome：Awesome集合了某个领域优势信息，信息质量极高。比如以下几个：

| 序号 | 名称                            | 简介                                                    | Github仓库地址                                               |
| ---- | ------------------------------- | ------------------------------------------------------- | ------------------------------------------------------------ |
| 1    | awesome-chatgpt                 | chatgpt优质资源合集，包括论文、AI相关公司、学习视频等。 | https://github.com/OpenMindClub/awesome-chatgpt              |
| 2    | Awesome-LLM                     | LLM精选列表，涵盖常见LLM介绍、LLM工具、LLM相关课程。    | https://github.com/Hannibal046/Awesome-LLM                   |
| 3    | Awesome-LLMs-Datasets           | 总结了现有最具有代表性LLMs文本数据集，非常全面。        | https://github.com/lmmlzn/Awesome-LLMs-Datasets              |
| 4    | awesome-generative-ai-guide     | 生成式AI相关最新研究、访谈等材料。                      | https://github.com/aishwaryanr/awesome-generative-ai-guide   |
| 5    | Awesome-Diffusion-Models        | Diffusion模型有关的资源和论文。                         | https://github.com/diff-usion/Awesome-Diffusion-Models       |
| 6    | awesome-artificial-intelligence | 集合AI相关的视频、书籍、讲座和论文等。                  | https://github.com/owainlewis/awesome-artificial-intelligence |
| 7    | Awesome ChatGPT Prompts         | 提示词合集。                                            | https://github.com/f/awesome-chatgpt-prompts                 |

##### Hugging Face：AI从业者都在这里

网址：https://huggingface.co

Hugging Face 的核心优势在于其 Transformers 库，提供了大量预训练的自然语言处理模型，使开发者能够轻松实现任务如文本分类、问答系统和翻译等，并且通过简单的 API 加速应用开发，同时拥有强大的社区支持和持续更新的模型资源。

下面介绍Hugging Face的三个使用技巧：

微调预训练模型：Hugging Face 的 Transformers 库包含大量的预训练大模型（如 BERT、GPT-3 等），这些模型可以通过少量数据进行微调，以适应特定任务。这种方法不仅节省计算资源，还能迅速获得高性能的结果。

利用社区共享资源：Hugging Face Hub 是一个开放的平台，用户可以上传并分享自己的模型和数据集。您可以直接从 Hub 下载并使用他人已经优化的大模型或经过清洗的数据集，这样可以加速开发过程，并且经常能找到针对特定领域或语言优化过的版本。

集成 Inference API 实现实时推理：通过使用 Hugging Face 的 Inference API，可以轻松将大模型集成到应用中，实现实时推理服务。这对于需要快速部署而不想管理复杂基础设施的项目特别有用，因为它提供了即插即用的解决方案。

##### Arxiv：获取AI前沿研究进展

网址：https://arxiv.org

ArXiv 是一个开放获取的学术论文平台，提供最新 AI 大模型研究，包括 GPT-3 和 BERT 等经典论文，是获取源头信息的首选。1991年8月至今，arXiv的总提交数量达到了235万篇。

2023年10月，arXiv达到了20,710篇新提交的月度记录，其中计算机科学、数学和物理学领域贡献了超过15,000篇。

作为非专业研究人员，并且时间有限，推荐你使用以下方法跟踪AI前沿进展：

- 活水快报。由活水智能开发，每天精选12篇AI相关的论文，网址：42digest.io，公众号「AI 研究速递」。
- 订阅关键词、查看顶级期刊筛选的论文。关键词：LLM or GenAI or AI site:arxiv.org、LLM site:nature.com、LLM site:scientificamerican.com 、LLM site:science.org、LLMsite:sciencedAIly.com、LLM site:cell.com
- Aminer筛选的论文。信息很全面，还可用于跟踪AI领域顶尖学者、研究机构等信息。网址：https://www.aminer.cn/topic

以上三个信息源，是跟踪AI大模型前言动态的首选。

#### 重要公司

除此之外，还可以跟踪顶尖AI公司的博客、阅读技术手册、阅读官方教程。博客代表了他们最新动态，非常值得关注。

我们按照AI大模型产业链整理了最值得关注的一批公司。整个产业链包括信息预处理、信息预训练、信息生成、信息微调与校验、信息的二次分发与加工、从信息世界到物理世界。

判断标准是这些公司在行业里面足够有影响力、已经盈利（包括有影响力但是没有盈利的）。

##### 数据预处理

（1）数据获取

- CrowdFlower (现为 [Figure Eight](https://www.figure-eight.com/) )：提供数据标注和清洗服务。
- [Kaggle Datasets](https://www.kaggle.com/datasets)：提供各种公开数据集。
- 八友科技：中国大模型公司头部数据提供商。

（2）数据标注

- [Appen](https://appen.com/)：全球领先的数据标注和人工智能训练数据提供商。
- [Scale AI](https://scale.com/)：为自动驾驶、计算机视觉等领域提供高质量的数据标注服务。
- [Labelbox](https://labelbox.com/)：一个用于图像、文本和视频标注的平台，支持机器学习模型的训练。

##### 大模型预训练

- [Open AI](https://openAI.com/)：代表大模型GPT-3.5，GPT-4，GPT-4o。

- [Anthropic](https://www.anthropic.com/)。代表大模型Claude 3、Claude 3.5 Sonnet。

##### 中间服务提供商

（1）向量数据库

- [MyScale](https://myscale.com/)：是一种新兴但有潜力的大规模分布式存储与计算平台，它在处理高维度数据方面表现出色，并且正在逐渐获得更多关注。
- [Pinecone](https://www.pinecone.io/)：一个完全托管的向量数据库，专为机器学习和AI应用设计，提供快速、高效的相似性搜索。
- [Milvus](https://milvus.io/)：一个开源向量数据库，支持大规模、高性能的相似性搜索和分析。它由Zilliz公司开发，并被广泛用于各种AI应用中。
- [Weaviate](https://weaviate.io/)：一个开源分布式向量搜索引擎，可以用于构建语义搜索、推荐系统等应用。它支持多种数据类型和集成。
- [Qdrant](https://qdrant.tech/)：开源矢量（嵌入）存储引擎，可以实现高效、实时地进行近邻检索，非常适合需要低延迟查询的大型机器学习模型部署场景。

（2）算力芯片

- [英伟达](https://www.nvidia.com/)：GPU（图形处理单元）市场领导者，广泛用于深度学习模型训练。

##### 推理、微调与部署分发

- [replicate](https://replicate.com/)：提供了一种简单的方法来运行机器学习模型，无需设置复杂的基础设施，非常适合快速原型设计和实验。
- [together. AI](https://www.together.AI/) ：一个专注于协作和优化数据科学工作流程的平台。它提供了一系列工具和服务，帮助团队更高效地管理、训练和部署机器学习模型。该平台旨在简化复杂的AI开发过程，并促进团队之间的合作。
- [Anyscale](https://www.anyscale.com/)：基于Ray框架，为开发者提供了简化的大规模分布式计算环境，使得构建、训练和部署大规模AI应用变得更加容易。

##### 运用开发

基于AI大模型开发的各类运用，以下是第一批享受AI时代发展红利的运用。

（1）文生图

- Midjourney：作为AI艺术生成领域的先锋，Midjourney以其高质量、艺术风格的图像生成能力在创意社区中广受欢迎，成为数字艺术家和设计师的首选工具，在市场上占据重要位置。网址：https://www.midjourney.com/home
- Stability AI：凭借其开源项目Stable Diffusion，Stability AI 在文本到图像生成领域树立了标杆，被广泛应用于学术研究和商业项目，是行业内公认的技术领导者，其技术被许多企业采用。网址：https://stability.AI/
- Civit AI ：通过提供一个社区驱动的平台，Civit AI 成为用户分享和探索多样化AI生成艺术作品的重要枢纽，在创意交流中占据重要位置，并推动了用户参与度和创新力。网址：https://civitAI.com/

（2）文生音乐

- suno：利用先进的AI技术，将文字描述转换为情感丰富且个性化的音乐作品，适用于各种创意项目。网址：https://suno.com/

（3）文生视频：

- runway：提供强大的机器学习工具，使用户能够通过简单的文本输入快速创建复杂且专业的视频内容，包括动画和特效。网址：https://runwayml.com/
- 可灵：可灵图生视频模型以卓越的图像理解能力为基础，将静态图像转化为生动的5秒精彩视频。配上创作者不同的文本输入，即生成多种多样的运动效果，让您的视觉创意无限延展。网址：https://klingAI.kuAIshou.com/

### 备查表3：推荐的 AI 相关书籍

1. 《What Is ChatGPT Doing … and Why Does It Work》 by Stephen Wolfram
 这本书从理论和实际角度详细解释了像ChatGPT这样的语言模型是如何工作的，非常适合希望理解大语言模型背后运作机制的读者。

2. 《The Age of Em: Work, Love, and Life When Robots Rule the Earth》 by Robin Hanson

Hanson从经济学和哲学的角度探讨了AI和大模型如何改变未来社会的工作和生活模式，适合对AI对社会变革感兴趣的读者。

3. 《Artificial Intelligence: A Guide for Thinking Humans》 by Melanie Mitchell
 Melanie 

Mitchell在这本书里用浅显易懂的语言解释了AI的基本原理，特别是关于深度学习和大模型的部分，不需要技术背景也能读懂。

4. 《You Look Like a Thing and I Love You: How Artificial Intelligence Works and Why It’s Making the World a Weirder Place》 by Janelle Shane

通过幽默的方式讲解AI如何运作，包括大模型的生成方式。适合对AI感兴趣但希望轻松愉快地理解其原理的人。

5. 《Grokking Deep Learning》 by Andrew W. Trask

这是一本相对通俗的深度学习入门书籍，Trask通过讲述核心概念，帮助读者从零开始理解AI和大模型的基本原理。

6.《Transformers for Natural Language Processing: Build Innovative Deep Neural Network Architectures for NLP with Python, PyTorch, TensorFlow, BERT, RoBERTa, and More》 by Denis Rothman

本书专注于Transformers架构，详细介绍了像BERT、GPT等预训练模型在NLP中的实际应用，提供了实际案例和代码，帮助读者快速理解并实践这些先进的模型。

7. 《Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence》 by Kate Crawford

这本书深入探讨了AI在社会、政治和环境中的影响，适合那些想从社会学和伦理学角度了解AI大模型的人。

8. 《Artificial Intelligence: A Very Short Introduction》 by Margaret A. Boden

Boden是一位认知科学和AI领域的专家，本书为读者提供了AI的全面概述，帮助理解大模型的理论背景。

9.《Hands-On Natural Language Processing with Python: A Practical Guide to Applying Deep Learning Architectures to Your NLP Applications》 by Rajesh Arumugam

本书提供了深度学习在NLP中的实践指导，帮助读者使用Python和流行的库（如PyTorch、TensorFlow）构建NLP系统。它专注于如何应用大模型进行语言处理任务，适合有编程基础的读者。

10. 《How to Create a Mind: The Secret of Human Thought Revealed》 by Ray Kurzweil

虽然这本书更偏向科幻思维，但Kurzweil详细讨论了人类思维与AI模型的异同，非常适合对认知和AI的结合感兴趣的读者。

### 备查表4：经典论文

AI大模型技术的发展中起到了至关重要的作用，还奠定了当前许多自然语言处理应用的基础，每一篇论文都代表了一个重要的里程碑。

1. Attention is All You Need (2017) - Vaswani et al.
   - 简介：提出了Transformer架构，通过自注意力机制解决了传统RNN和CNN的局限性。
   - [论文链接](https://arxiv.org/abs/1706.03762)
   
2. Deep contextualized word representations (2018) - Peters et al.
   - 简介：引入了基于双向LSTM的ELMo模型，通过上下文进行动态词向量表示，极大地提升了下游NLP任务的表现。
   - [论文链接](https://arxiv.org/abs/1802.05365)
   
3. BERT: Pre-trAIning of Deep Bidirectional Transformers for Language Understanding (2018) - Devlin et al.
   - 简介：提出了BERT模型，通过双向Transformer的预训练方式显著提高了多种自然语言处理任务的效果。
   - [论文链接](https://arxiv.org/abs/1810.04805)
   
4. Improving Language Understanding by Generative Pre-TrAIning (2018) - Radford et al.
   - 简介：提出了生成式预训练模型GPT，通过无监督预训练和有监督微调提升语言理解能力，开创了生成式预训练模型的先河。
   - [论文链接](https://openAI.com/research/language-unsupervised)
   
5. RoBERTa: A Robustly Optimized BERT PretrAIning Approach (2019) - Liu et al.
   - 简介：对BERT预训练方法进行了优化，通过更大的训练数据和更长的训练时间显著提高了模型性能。
   - [论文链接](https://arxiv.org/abs/1907.11692)
   
6. FAISS: A Library for Efficient Similarity Search and Clustering of Dense Vectors (2017) - Johnson et al.
   - 简介：向量数据库方面经典论文。FAISS是一个高效的相似性搜索和密集向量聚类的库，它被广泛用于在大规模数据集中快速检索向量。
   - [论文链接](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/)
   
7. Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer (2019) - Raffel et al.
   - 简介：提出了T5模型，统一了文本生成和文本理解任务，通过“文本到文本”的转换方式处理各种NLP任务。
   - [论文链接](https://arxiv.org/abs/1910.10683)
   
8. GPT-2: Language Models are Unsupervised Multitask Learners (2019) - Radford et al.
   - 简介：提出了GPT-2模型，通过无监督学习实现了多任务处理，显著提升了语言生成的质量。
   - [论文链接](https://openAI.com/research/language-unsupervised)
   
9. Scaling Laws for Neural Language Models (2020) - Kaplan et al.
   - 简介：探讨了神经语言模型的规模与性能之间的关系，为大规模模型的设计和训练提供了理论依据。
   - [论文链接](https://arxiv.org/abs/2001.08361)
   
11. Electra: Pre-trAIning Text Encoders as Discriminators Rather Than Generators (2020) - Clark et al.
    - 简介：提出了Electra模型，通过预训练判别器而非生成器的方法，提高了预训练的效率和效果。
    - [论文链接](https://arxiv.org/abs/2003.10555)
    
12. Language Models are Few-Shot Learners (2020) - Brown et al.
    - 简介：展示了GPT-3模型，通过庞大的参数量和无监督预训练，在少量示例下实现了卓越的任务表现。
    - [论文链接](https://arxiv.org/abs/2005.14165)
    
13. What does BERT look at? An Analysis of BERT's Attention(2019) - Clark et al.
    - 简介：深入分析了BERT模型内部的工作机制，揭示了其内部表示和注意力模式的特点。
    - [论文链接](https://arxiv.org/abs/1906.04341)
    
14. DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter (2019) - Sanh et al.
    - 简介：提出了DistilBERT模型，通过知识蒸馏技术减小了BERT模型的大小，同时保持了较高的性能。
    - [论文链接](https://arxiv.org/abs/1910.01108)
    
15. Retrieval-Augmented Generation for Language Models (2020) - Lewis et al.
    - 简介：提出了RAG模型，通过结合检索技术和生成模型，增强了模型在回答问题时的信息准确性和丰富性。
    - [论文链接](https://arxiv.org/abs/2005.11401)
    
16. Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity (2021) - Fedus et al.
    - 简介：通过引入稀疏激活技术实现了高效的超大规模模型训练，为大规模模型的训练提供了一种新的方法。
    - [论文链接](https://arxiv.org/abs/2101.03961)
    
17. Perceiver: General Perception with Iterative Attention (2021) - Jaegle et al.
    - 简介：提出了Perceiver模型，通过迭代注意力机制处理任意类型的数据输入，为构建通用感知模型提供了新思路。
    - [论文链接](https://arxiv.org/abs/2103.03206)
    
19. Training Compute-Optimal Large Language Models(2022) - Hoffmann et al.
    - 简介：研究了大规模模型的训练效率，提出了在固定计算预算下，更多数据和较小模型的训练策略，为训练大规模模型提供了新思路。
    - [论文链接](https://arxiv.org/abs/2203.15556)
    
20. PaLM: Scaling Language Modeling with Pathways (2022) - Chowdhery et al.
    - 简介：展示了PaLM模型如何利用Pathways架构实现多任务和多模态的高效训练，推动了大规模多模态模型的发展。
    - [论文链接](https://arxiv.org/abs/2204.02311)
    
21. Scaling Language Models: Methods, Analysis & Insights from Training Gopher (2022) - Rae et al.
    - 简介：详细探讨了大规模语言模型的训练方法和扩展策略，通过对280B参数模型的训练过程进行深入分析，为理解和改进大型语言模型的性能提供了重要见解。
    - [论文链接](https://arxiv.org/abs/2112.11446)
    
22. GPT-4 Technical Report (2023) - OpenAI
    - 简介：报告了GPT-4的开发，作为多模态大规模模型，它在多个专业和学术基准测试中表现出人类级别的性能，是GPT系列的最新发展。
    - [论文链接](https://cdn.openAI.com/papers/gpt-4.pdf)
    
23. LLaMA: Open and Accurate Large Language Models (2023) - Meta AI
    - 简介：介绍了LLaMA模型，这是一个开源的大规模语言模型，旨在提高模型的准确性和透明度。
    - [论文链接](https://arxiv.org/abs/2302.13971)

### 备查表5： AI 时代的技术栈

AI 时代的技术栈以fastapi+python为主。以下整理常见技术栈。

通用大模型：

1. [OpenAI API](https://beta.openAI.com/docs)：以OpenAI的API为代表，用于开发各种智能应用。

前端：
1. [Vercel](https://vercel.com)：一个用于部署前端应用的平台，支持自动化部署和无服务器功能。
2. [Next.js](https://nextjs.org)：一个React框架，用于构建静态和动态网站。
3. [TAIlwind CSS](https://tAIlwindcss.com)：一个实用的CSS框架，用于快速构建自定义用户界面。

后端：

1. [FastAPI](https://fastapi.tiangolo.com)：一个现代的、快速（高性能）的Python web框架，用于构建API。

数据库：
1. [Pinecone](https://www.pinecone.io)：一个向量数据库，用于高效存储和查询向量数据。
2. [pgvector](https://github.com/pgvector/pgvector)：一个PostgreSQL扩展，用于向量相似性搜索。

算法：

1. [Python](https://www.python.org)和[Rust](https://www.rust-lang.org)：Python用于一般算法开发，Rust用于高性能代码。

服务器：
1. [Vercel](https://vercel.com)：国外服务器，用于部署全球化应用。
2. [腾讯云](https://cloud.tencent.com)：国内服务器，用于在中国大陆地区部署应用。
3. [Sealos](https://github.com/fanux/sealos)：一个开源的云计算平台，用于构建和管理Kubernetes集群。

存储：
1. [群晖](https://www.synology.com/zh-cn)：本地存储NAS，用于本地数据存储和备份。
2. [AWS](https://aws.amazon.com)和[腾讯云](https://cloud.tencent.com)：用于云端数据存储。

算力：

1. [NVIDIA](https://www.nvidia.com)：用于深度学习模型的训练和推理。

模型训练架构：

1. [Transformer](https://arxiv.org/abs/1706.03762)：一种用于自然语言处理和生成任务的模型架构。

模型集市：

1. [Hugging Face](https://huggingface.co)：一个开放的机器学习平台和社区，提供各种预训练模型。

模型开发：

1. [Python](https://www.python.org)与[Rust](https://www.rust-lang.org)：用于开发和优化机器学习模型。

支付：

1. [Stripe](https://stripe.com/zh-us)：一个在线支付处理平台，支持全球支付。

### 备查表6：课程推荐

推荐查看DeepLearning上的课程，DeepLearning是由吴恩达教授创建，是目前最好的人工智能教育平台之一。上面课程内容多样，适合软件开发者、不懂AI的均有课程对应。课程制作优良，配备练习题目，方便你检查学习成果。

以下是部分课程：

| 课程名称                                                     | 主要内容                                                     | 适合人群                                                     | 链接                                                         |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 面向所有人的生成式人工智能（Generative AI for Everyone）   | 了解生成式人工智能的运作方式，并学习如何在生活和工作中应用它 | 任何对生成式AI感兴趣的人                                   | https://www.deeplearning.AI/courses/generative-AI-for-everyone/ |
| 适合初学者的 AI Python（AI Python for Beginners）        | 如何在AI帮助下编写python                                   | 任何对 AI 和 Python 编程感到好奇的人                       | https://www.deeplearning.AI/short-courses/AI-python-for-beginners/ |
| 面向开发人员的 ChatGPT 提示工程（ChatGPT Prompt Engineering for Developers） | 如何使用提示词发展AI技能                                   | 开发人员                                                     | https://www.deeplearning.AI/short-courses/chatgpt-prompt-engineering-for-developers/ |
| 微调大型语言模型（Finetuning Large Language Models）         | 了解何时应用微调LLMs准备用于微调的数据LLM训练和评估您的数据  | 想要了解微调的技术和应用，熟悉 Python，并了解 PyTorch 等深度学习框架的学习者。 | https://www.deeplearning.AI/short-courses/finetuning-large-language-models/ |
| RAG 的知识图谱（Knowledge Graphs for RAG）                   | 如何使用知识图谱来发现数据中更深入的见解，并通过结构化的相关上下文提高性能LLMs。 | 想要了解知识图谱如何工作，如何使用它们进行构建，并创建更好的RAG应用程序的人。 | https://www.deeplearning.AI/short-courses/knowledge-graphs-rag/ |

除了课程外，更推荐查看各大公司的技术手册、博客、直接和开发者交流，并且动手跑程序、构建产品、直接写教材，开设课程，这比学习课程快多了。

- openAI-cookbook：https://github.com/openAI/openAI-cookbook
- Gemini API Cookbook：https://github.com/google-gemini/cookbook
- Mistral Cookbook：https://github.com/mistralAI/cookbook
- 开源 AI Cookbook：https://github.com/huggingface/cookbook
- anthropic-cookbook：https://github.com/anthropics/anthropic-cookbook
- cohere Cookbooks：https://docs.cohere.com/docs/cookbooks

你也可以查看Github上相关的课程：

- llm-course：使用路线图和 Colab 笔记本进入大型语言模型 （LLMs） 的课程。网址：https://github.com/mlabonne/llm-course
- 前特斯拉高级 AI 总监 Andrej Karpthy揭秘OpenAI大模型原理和训练过程。网址：https://www.youtube.com/watch?v=zjkBMFhNj_g
- generative-AI-for-beginners：由微软推出，十八节课让你轻松了解生成式AI。网址：https://github.com/microsoft/generative-AI-for-beginners
- AI-For-Beginners：一个为初学者设计的12周AI课程，包括TensorFlow和PyTorch实践，覆盖深度学习和AI伦理。网址：https://github.com/microsoft/AI-For-Beginners
- Anthropic的教育课程：适合开发者，包括四门课程，包括开发基础知识、提示工程、工作流等。网址：https://github.com/anthropics/courses

## 脚注

[^1]: https://github.blog/news-insights/research/the-state-of-open-source-and-AI/#the-explosive-growth-of-generative-AI-in-2023

[^2 ]：https://medium.com/the-generator/the-perfect-prompt-prompt-engineering-cheat-sheet-d0b9c62a2bba