# 3.3.3 LocalAI

LocalAI是一个开源工具，旨在在本地环境中运行大型语言模型，支持多种开源模型，可以通过Docker容器部署，并且提供了与 OpenAI API 兼容的接口。

LocalAI更适合开发者二次开发，具体可参考（https://localai.io/）。

本地运行大模型还支持上传文档，与文档对话，这些文档始终在电脑本地，处理文档也不需要消耗API。

如果你想获取更多本地运行大模型方法，可以参考这个链接：https://github.com/vince-lam/awesome-local-llms